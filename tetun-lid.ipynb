{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing.process_data import ProcessData\n",
    "from training.train_model import TrainModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from text_processing.process_data import ProcessData\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classes\n",
    "process_data = ProcessData()\n",
    "# Since we trained the model on chars and words levels, we do not normalize the sentence length.\n",
    "dataset = process_data.initial_clean_data_with_count()\n",
    "train_models = TrainModel(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dili  outubru gabinete apoiu atividade kónjuge...</td>\n",
       "      <td>tet</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>treinamentu ne’e ninia objetivu prinsipál mak ...</td>\n",
       "      <td>tet</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iha loron daruak hosi treinamentu ne’e partisi...</td>\n",
       "      <td>tet</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>partisipante na’in iha treinamentu ne’e mai ho...</td>\n",
       "      <td>tet</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komunidade iha suku bikeli ho makadade agrades...</td>\n",
       "      <td>tet</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence language  sentence_length\n",
       "0  dili  outubru gabinete apoiu atividade kónjuge...      tet              275\n",
       "1  treinamentu ne’e ninia objetivu prinsipál mak ...      tet              232\n",
       "2  iha loron daruak hosi treinamentu ne’e partisi...      tet              288\n",
       "3  partisipante na’in iha treinamentu ne’e mai ho...      tet               82\n",
       "4  komunidade iha suku bikeli ho makadade agrades...      tet              320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial data\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is cleaned.\n"
     ]
    }
   ],
   "source": [
    "# Confirm that data is cleaned.\n",
    "clean = dataset[(dataset[\"sentence\"] == \"\") & (dataset[\"sentence\"] == \" \")]\n",
    "try:\n",
    "    assert len(clean) == 0\n",
    "    print(\"The data is cleaned.\")\n",
    "except AssertionError:\n",
    "    print(\"The data is NOT cleaned.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 80362\n",
      "Dev set size: 17220\n",
      "Test set size: 17221\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to train, development(dev)/validation, and test sets\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = train_models.train_dev_test_split(0.3, 0.5)\n",
    "\n",
    "# print the sizes of the resulting sets\n",
    "print(\"Train set size:\", len(X_train))\n",
    "print(\"Dev set size:\", len(X_dev))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC()\n",
      "Analyzer: char_wb\n",
      "\tn_gram 1 --> accuracy:  0.9772\n",
      "\tn_gram 2 --> accuracy:  0.9909\n",
      "\tn_gram 3 --> accuracy:  0.9948\n",
      "\tn_gram 4 --> accuracy:  0.9951\n",
      "\tn_gram 5 --> accuracy:  0.9954\n",
      "\tn_gram 6 --> accuracy:  0.9948\n",
      "Analyzer: word\n",
      "\tn_gram 1 --> accuracy:  0.9926\n",
      "\tn_gram 2 --> accuracy:  0.9639\n",
      "\tn_gram 3 --> accuracy:  0.8298\n",
      "\tn_gram 4 --> accuracy:  0.5306\n",
      "\tn_gram 5 --> accuracy:  0.4170\n",
      "\tn_gram 6 --> accuracy:  0.3725\n",
      "Model: LogisticRegression(multi_class='ovr')\n",
      "Analyzer: char_wb\n",
      "\tn_gram 1 --> accuracy:  0.9765\n",
      "\tn_gram 2 --> accuracy:  0.9912\n",
      "\tn_gram 3 --> accuracy:  0.9941\n",
      "\tn_gram 4 --> accuracy:  0.9949\n",
      "\tn_gram 5 --> accuracy:  0.9946\n",
      "\tn_gram 6 --> accuracy:  0.9931\n",
      "Analyzer: word\n",
      "\tn_gram 1 --> accuracy:  0.9898\n",
      "\tn_gram 2 --> accuracy:  0.9459\n",
      "\tn_gram 3 --> accuracy:  0.7962\n",
      "\tn_gram 4 --> accuracy:  0.4697\n",
      "\tn_gram 5 --> accuracy:  0.3785\n",
      "\tn_gram 6 --> accuracy:  0.3503\n",
      "Model: MultinomialNB()\n",
      "Analyzer: char_wb\n",
      "\tn_gram 1 --> accuracy:  0.9388\n",
      "\tn_gram 2 --> accuracy:  0.9880\n",
      "\tn_gram 3 --> accuracy:  0.9936\n",
      "\tn_gram 4 --> accuracy:  0.9950\n",
      "\tn_gram 5 --> accuracy:  0.9956\n",
      "\tn_gram 6 --> accuracy:  0.9955\n",
      "Analyzer: word\n",
      "\tn_gram 1 --> accuracy:  0.9948\n",
      "\tn_gram 2 --> accuracy:  0.9680\n",
      "\tn_gram 3 --> accuracy:  0.7681\n",
      "\tn_gram 4 --> accuracy:  0.4966\n",
      "\tn_gram 5 --> accuracy:  0.3899\n",
      "\tn_gram 6 --> accuracy:  0.3557\n"
     ]
    }
   ],
   "source": [
    "# Compare various models\n",
    "\n",
    "model_lists = [LinearSVC(), LogisticRegression(multi_class=\"ovr\"), MultinomialNB()]\n",
    "analyzers = [\"char_wb\", \"word\"]\n",
    "\n",
    "train_models.compare_models(model_lists, analyzers, 1, 6, 1, X_train, y_train, X_dev, y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9955865272938443\n",
      "Confusion Matrix:  [[5257    6    3    3]\n",
      " [  24 4766    4    0]\n",
      " [  15    7 4425    2]\n",
      " [   3    0    9 2696]]\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "          en       0.99      1.00      0.99      5269\n",
      "          id       1.00      0.99      1.00      4794\n",
      "          pt       1.00      0.99      1.00      4449\n",
      "         tet       1.00      1.00      1.00      2708\n",
      "\n",
      "    accuracy                           1.00     17220\n",
      "   macro avg       1.00      1.00      1.00     17220\n",
      "weighted avg       1.00      1.00      1.00     17220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the best model, train and evaluate it using the dev set\n",
    "\n",
    "# Train the model\n",
    "model = train_models.train_model(\n",
    "    TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(5, 5)), MultinomialNB(), X_train, y_train\n",
    ")\n",
    "\n",
    "# Evaluate the model using dev set\n",
    "train_models.evaluate_model(model, X_dev, y_dev)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9959932640380931\n",
      "Confusion Matrix:  [[5329    4    1    2]\n",
      " [  23 4666    2    1]\n",
      " [  20    4 4448    5]\n",
      " [   3    1    3 2709]]\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "          en       0.99      1.00      1.00      5336\n",
      "          id       1.00      0.99      1.00      4692\n",
      "          pt       1.00      0.99      1.00      4477\n",
      "         tet       1.00      1.00      1.00      2716\n",
      "\n",
      "    accuracy                           1.00     17221\n",
      "   macro avg       1.00      1.00      1.00     17221\n",
      "weighted avg       1.00      1.00      1.00     17221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using test set\n",
    "train_models.evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 classification: ['tet']\n",
      "Test 2 classification: ['tet']\n"
     ]
    }
   ],
   "source": [
    "test1 = model.predict([\"Organizasaun mundial saúde\"])\n",
    "test2 = model.predict([\"Tribunál rekursu rejeita kandidatura partidu\"])\n",
    "print(f\"Test 1 classification: {test1}\\nTest 2 classification: {test2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deklarasaun Universál Direitus Umanus\n",
      "en 1.7198102347965515e-05\n",
      "id 7.656943219400005e-05\n",
      "pt 0.0001802486040840422\n",
      "tet 0.9997259838613715\n",
      "Indonesia merupakan negara terluas ke-14 sekaligus\n",
      "en 1.3050918693531165e-07\n",
      "id 0.9999995025902451\n",
      "pt 9.055449712082101e-08\n",
      "tet 2.7634607120579004e-07\n",
      "A língua portuguesa, também designada português, é uma língua\n",
      "en 0.00018657712215813118\n",
      "id 2.970099994212303e-05\n",
      "pt 0.998175916996359\n",
      "tet 0.0016078048815381433\n",
      "Deklarasaun ne'e inklui artigu 30 ne'ebé esplika Asembleia Jerál\n",
      "en 2.916091141335691e-08\n",
      "id 4.085156091273892e-08\n",
      "pt 1.4132462405706621e-07\n",
      "tet 0.9999997886629056\n",
      "Can we feed a future population of 10 billion people a healthy?\n",
      "en 0.9999978448630447\n",
      "id 1.321850425292166e-07\n",
      "pt 1.061105899088093e-06\n",
      "tet 9.61846016528177e-07\n"
     ]
    }
   ],
   "source": [
    "input = [\n",
    "    \"Deklarasaun Universál Direitus Umanus\",\n",
    "    \"Indonesia merupakan negara terluas ke-14 sekaligus\",\n",
    "    \"A língua portuguesa, também designada português, é uma língua\",\n",
    "    \"Deklarasaun ne'e inklui artigu 30 ne'ebé esplika Asembleia Jerál\",\n",
    "    \"Can we feed a future population of 10 billion people a healthy?\",\n",
    "]\n",
    "\n",
    "# Naive Bayes and Logistic Regression\n",
    "pred_probs = model.predict_proba(input)\n",
    "\n",
    "for i, probs in enumerate(pred_probs):\n",
    "    print(input[i])\n",
    "    for j, lang in enumerate(model.classes_):\n",
    "        print(lang, probs[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - LinearSVC\n",
    "pred_result = model.predict(input)\n",
    "pred_probability = model.decision_function(input)\n",
    "for i in range(len(input)):\n",
    "    print(\n",
    "        f\"{input[i]} ---> {pred_result[i]} ---> {np.argmax(pred_probability[i])} --> {pred_probability[i]} \"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model [if required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_best/tet-lid-model_NB_best_ng5chars.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# save the model to a file\n",
    "joblib.dump(model, \"model_best/tet-lid-model_NB_best_ng5chars.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the save model from a file\n",
    "import joblib\n",
    "\n",
    "saved_model = joblib.load(\"model_best/tet-lid-model_NB_best_ng5chars.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "text = [\"Timor-Leste\", \"Timor\", \"Lei\"]\n",
    "\n",
    "# plain_text = unidecode(text)\n",
    "# plain_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timor-Leste\n",
      "en 5.971441277656112e-07\n",
      "id 2.524699071902872e-06\n",
      "pt 2.5094790700185165e-06\n",
      "tet 0.9999943686777295\n",
      "Timor\n",
      "en 0.0007093783786956153\n",
      "id 0.006613671115733073\n",
      "pt 0.0006555447235547801\n",
      "tet 0.9920214057820171\n",
      "Lei\n",
      "en 0.02498752277221515\n",
      "id 0.021932794497354923\n",
      "pt 0.4597678041996972\n",
      "tet 0.4933118785307327\n"
     ]
    }
   ],
   "source": [
    "pred_probs = saved_model.predict_proba(text)\n",
    "\n",
    "for i, probs in enumerate(pred_probs):\n",
    "    print(text[i])\n",
    "    for j, lang in enumerate(saved_model.classes_):\n",
    "        print(lang, probs[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tetun-lid-2afysUYK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2911380a96f00ac3d85554f7d01794a294b1d45d66fe7770d1ab4e2af95b714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
